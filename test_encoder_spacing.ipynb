{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63e942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad4cc1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/saikiran.tedla/anyedit/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from: ./models/Wan-AI/Wan2.2-TI2V-5B/models_t5_umt5-xxl-enc-bf16.pth\n",
      "    model_name: wan_video_text_encoder model_class: WanTextEncoder\n",
      "    The following models are loaded: ['wan_video_text_encoder'].\n",
      "Loading models from: ['./models/Wan-AI/Wan2.2-TI2V-5B/diffusion_pytorch_model-00003-of-00003-bf16.safetensors', './models/Wan-AI/Wan2.2-TI2V-5B/diffusion_pytorch_model-00002-of-00003-bf16.safetensors', './models/Wan-AI/Wan2.2-TI2V-5B/diffusion_pytorch_model-00001-of-00003-bf16.safetensors']\n",
      "    model_name: wan_video_dit model_class: WanModel\n",
      "        This model is initialized with extra kwargs: {'has_image_input': False, 'patch_size': [1, 2, 2], 'in_dim': 48, 'dim': 3072, 'ffn_dim': 14336, 'freq_dim': 256, 'text_dim': 4096, 'out_dim': 48, 'num_heads': 24, 'num_layers': 30, 'eps': 1e-06, 'seperated_timestep': True, 'require_clip_embedding': False, 'require_vae_embedding': False, 'fuse_vae_embedding_in_latents': True}\n",
      "    The following models are loaded: ['wan_video_dit'].\n",
      "Loading models from: ./models/Wan-AI/Wan2.2-TI2V-5B/Wan2.2_VAE.pth\n",
      "    model_name: wan_video_vae model_class: WanVideoVAE38\n",
      "    The following models are loaded: ['wan_video_vae'].\n",
      "Using wan_video_text_encoder from ./models/Wan-AI/Wan2.2-TI2V-5B/models_t5_umt5-xxl-enc-bf16.pth.\n",
      "Using wan_video_dit from ['./models/Wan-AI/Wan2.2-TI2V-5B/diffusion_pytorch_model-00003-of-00003-bf16.safetensors', './models/Wan-AI/Wan2.2-TI2V-5B/diffusion_pytorch_model-00002-of-00003-bf16.safetensors', './models/Wan-AI/Wan2.2-TI2V-5B/diffusion_pytorch_model-00001-of-00003-bf16.safetensors'].\n",
      "Using wan_video_vae from ./models/Wan-AI/Wan2.2-TI2V-5B/Wan2.2_VAE.pth.\n",
      "No wan_video_image_encoder models available.\n",
      "No wan_video_motion_controller models available.\n",
      "No wan_video_vace models available.\n",
      "No wans2v_audio_encoder models available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from diffsynth import save_video, VideoData, load_state_dict\n",
    "from diffsynth.pipelines.wan_video_new import WanVideoPipeline, ModelConfig\n",
    "from modelscope import dataset_snapshot_download\n",
    "\n",
    "\n",
    "pipe = WanVideoPipeline.from_pretrained(\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device=\"cuda\",\n",
    "    model_configs=[\n",
    "        ModelConfig(model_id=\"Wan-AI/Wan2.2-TI2V-5B\", origin_file_pattern=\"models_t5_umt5-xxl-enc-bf16.pth\", offload_device=\"cpu\", skip_download=True),\n",
    "        ModelConfig(model_id=\"Wan-AI/Wan2.2-TI2V-5B\", origin_file_pattern=\"diffusion_pytorch_model*.safetensors\", offload_device=\"cpu\", skip_download=True),\n",
    "        ModelConfig(model_id=\"Wan-AI/Wan2.2-TI2V-5B\", origin_file_pattern=\"Wan2.2_VAE.pth\", offload_device=\"cpu\", skip_download=True),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f6dc6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipe device: cuda\n",
      "Frame 0: PSNR = 28.68 dB\n",
      "Frame 1: PSNR = 29.10 dB\n",
      "Frame 2: PSNR = 26.85 dB\n",
      "Frame 3: PSNR = 27.01 dB\n",
      "Frame 4: PSNR = 28.23 dB\n",
      "Frame 5: PSNR = 25.49 dB\n",
      "Frame 6: PSNR = 26.00 dB\n",
      "Frame 7: PSNR = 26.71 dB\n",
      "Frame 8: PSNR = 27.86 dB\n",
      "Frame 9: PSNR = 24.79 dB\n",
      "Frame 10: PSNR = 26.67 dB\n",
      "Frame 11: PSNR = 26.84 dB\n",
      "Frame 12: PSNR = 28.00 dB\n",
      "Frame 13: PSNR = 26.01 dB\n",
      "Frame 14: PSNR = 27.12 dB\n",
      "Frame 15: PSNR = 26.53 dB\n",
      "Frame 16: PSNR = 27.31 dB\n",
      "Frame 17: PSNR = 27.66 dB\n",
      "Frame 18: PSNR = 29.47 dB\n",
      "Frame 19: PSNR = 29.84 dB\n",
      "Frame 20: PSNR = 30.41 dB\n",
      "Frame 21: PSNR = 30.00 dB\n",
      "Frame 22: PSNR = 30.83 dB\n",
      "Frame 23: PSNR = 31.48 dB\n",
      "Frame 24: PSNR = 32.39 dB\n",
      "Frame 25: PSNR = 29.11 dB\n",
      "Frame 26: PSNR = 30.09 dB\n",
      "Frame 27: PSNR = 30.56 dB\n",
      "Frame 28: PSNR = 31.82 dB\n",
      "Frame 29: PSNR = 29.77 dB\n",
      "Frame 30: PSNR = 30.26 dB\n",
      "Frame 31: PSNR = 29.63 dB\n",
      "Frame 32: PSNR = 32.43 dB\n",
      "Frame 33: PSNR = 32.16 dB\n",
      "Frame 34: PSNR = 33.94 dB\n",
      "Frame 35: PSNR = 34.26 dB\n",
      "Frame 36: PSNR = 34.90 dB\n",
      "Frame 37: PSNR = 33.89 dB\n",
      "Frame 38: PSNR = 32.21 dB\n",
      "Frame 39: PSNR = 32.06 dB\n",
      "Frame 40: PSNR = 33.21 dB\n",
      "Frame 41: PSNR = 35.26 dB\n",
      "Frame 42: PSNR = 35.78 dB\n",
      "Frame 43: PSNR = 36.50 dB\n",
      "Frame 44: PSNR = 36.71 dB\n",
      "Frame 45: PSNR = 35.87 dB\n",
      "Frame 46: PSNR = 36.24 dB\n",
      "Frame 47: PSNR = 36.71 dB\n",
      "Frame 48: PSNR = 37.08 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving video: 100%|██████████| 49/49 [00:00<00:00, 113.13it/s]\n",
      "Saving video: 100%|██████████| 49/49 [00:00<00:00, 108.59it/s]\n"
     ]
    }
   ],
   "source": [
    "#read in mp4 video\n",
    "mp4_path = \"/data2/saikiran.tedla/hdrvideo/diff/stuttgart_input.mp4\"\n",
    "frames = VideoData(mp4_path, height=480, width=832).raw_data()\n",
    "print(\"pipe device:\", pipe.device)\n",
    "input_video = pipe.preprocess_video(frames)\n",
    "pipe.load_models_to_device([\"vae\"])\n",
    "\n",
    "# ensure the VAE is actually on the GPU in the right dtype\n",
    "pipe.vae = pipe.vae.to(device=pipe.device)\n",
    "pipe.vae.eval()  # optional but good practice\n",
    "\n",
    "input_latents = pipe.vae.encode(input_video, device=pipe.device, tiled=False).to(dtype=pipe.torch_dtype, device=pipe.device)\n",
    "output_video = pipe.vae.decode(input_latents, device=pipe.device, tiled=False).to(dtype=torch.float32, device=\"cpu\")\n",
    "output_video = pipe.vae_output_to_video(output_video)\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "def psnr(img1, img2):\n",
    "    \"\"\"Compute PSNR between two numpy arrays (H,W,C).\"\"\"\n",
    "    mse = np.mean((img1.astype(np.float32) - img2.astype(np.float32)) ** 2)\n",
    "    if mse == 0:\n",
    "        return float(\"inf\")  # identical images\n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "# compute per-frame PSNR\n",
    "psnr_values = []\n",
    "for i, (f1, f2) in enumerate(zip(frames, output_video)):\n",
    "    arr1 = np.array(f1)  # convert PIL → numpy\n",
    "    arr2 = np.array(f2)\n",
    "    value = psnr(arr1, arr2)\n",
    "    psnr_values.append(value)\n",
    "    print(f\"Frame {i}: PSNR = {value:.2f} dB\")\n",
    "\n",
    "\n",
    "# save the output video\n",
    "save_video(frames, \"input_video.mp4\", fps=15)\n",
    "save_video(output_video, \"output_video.mp4\", fps=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anyedit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
