{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a63e942b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ad4cc1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from: ./models/Wan-AI/Wan2.2-TI2V-5B/models_t5_umt5-xxl-enc-bf16.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model_name: wan_video_text_encoder model_class: WanTextEncoder\n",
      "    The following models are loaded: ['wan_video_text_encoder'].\n",
      "Loading models from: ['./models/Wan-AI/Wan2.2-TI2V-5B/diffusion_pytorch_model-00003-of-00003-bf16.safetensors', './models/Wan-AI/Wan2.2-TI2V-5B/diffusion_pytorch_model-00002-of-00003-bf16.safetensors', './models/Wan-AI/Wan2.2-TI2V-5B/diffusion_pytorch_model-00001-of-00003-bf16.safetensors']\n",
      "    model_name: wan_video_dit model_class: WanModel\n",
      "        This model is initialized with extra kwargs: {'has_image_input': False, 'patch_size': [1, 2, 2], 'in_dim': 48, 'dim': 3072, 'ffn_dim': 14336, 'freq_dim': 256, 'text_dim': 4096, 'out_dim': 48, 'num_heads': 24, 'num_layers': 30, 'eps': 1e-06, 'seperated_timestep': True, 'require_clip_embedding': False, 'require_vae_embedding': False, 'fuse_vae_embedding_in_latents': True}\n",
      "    The following models are loaded: ['wan_video_dit'].\n",
      "Loading models from: ./models/Wan-AI/Wan2.2-TI2V-5B/Wan2.2_VAE.pth\n",
      "    model_name: wan_video_vae model_class: WanVideoVAE38\n",
      "    The following models are loaded: ['wan_video_vae'].\n",
      "Using wan_video_text_encoder from ./models/Wan-AI/Wan2.2-TI2V-5B/models_t5_umt5-xxl-enc-bf16.pth.\n",
      "Using wan_video_dit from ['./models/Wan-AI/Wan2.2-TI2V-5B/diffusion_pytorch_model-00003-of-00003-bf16.safetensors', './models/Wan-AI/Wan2.2-TI2V-5B/diffusion_pytorch_model-00002-of-00003-bf16.safetensors', './models/Wan-AI/Wan2.2-TI2V-5B/diffusion_pytorch_model-00001-of-00003-bf16.safetensors'].\n",
      "Using wan_video_vae from ./models/Wan-AI/Wan2.2-TI2V-5B/Wan2.2_VAE.pth.\n",
      "No wan_video_image_encoder models available.\n",
      "No wan_video_motion_controller models available.\n",
      "No wan_video_vace models available.\n",
      "No wans2v_audio_encoder models available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WanVideoVAE38(\n",
       "  (model): VideoVAE38_(\n",
       "    (encoder): Encoder3d_38(\n",
       "      (conv1): CausalConv3d(12, 160, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (downsamples): Sequential(\n",
       "        (0): Down_ResidualBlock(\n",
       "          (avg_shortcut): AvgDown3D()\n",
       "          (downsamples): Sequential(\n",
       "            (0): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(160, 160, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(160, 160, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (1): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(160, 160, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(160, 160, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (2): Resample38(\n",
       "              (resample): Sequential(\n",
       "                (0): ZeroPad2d((0, 1, 0, 1))\n",
       "                (1): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Down_ResidualBlock(\n",
       "          (avg_shortcut): AvgDown3D()\n",
       "          (downsamples): Sequential(\n",
       "            (0): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(160, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): CausalConv3d(160, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (1): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (2): Resample38(\n",
       "              (resample): Sequential(\n",
       "                (0): ZeroPad2d((0, 1, 0, 1))\n",
       "                (1): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2))\n",
       "              )\n",
       "              (time_conv): CausalConv3d(320, 320, kernel_size=(3, 1, 1), stride=(2, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): Down_ResidualBlock(\n",
       "          (avg_shortcut): AvgDown3D()\n",
       "          (downsamples): Sequential(\n",
       "            (0): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(320, 640, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(640, 640, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): CausalConv3d(320, 640, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (1): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(640, 640, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(640, 640, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (2): Resample38(\n",
       "              (resample): Sequential(\n",
       "                (0): ZeroPad2d((0, 1, 0, 1))\n",
       "                (1): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2))\n",
       "              )\n",
       "              (time_conv): CausalConv3d(640, 640, kernel_size=(3, 1, 1), stride=(2, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Down_ResidualBlock(\n",
       "          (avg_shortcut): AvgDown3D()\n",
       "          (downsamples): Sequential(\n",
       "            (0): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(640, 640, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(640, 640, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (1): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(640, 640, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(640, 640, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (middle): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): RMS_norm()\n",
       "            (1): SiLU()\n",
       "            (2): CausalConv3d(640, 640, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "            (3): RMS_norm()\n",
       "            (4): SiLU()\n",
       "            (5): Dropout(p=0.0, inplace=False)\n",
       "            (6): CausalConv3d(640, 640, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): RMS_norm()\n",
       "          (to_qkv): Conv2d(640, 1920, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): RMS_norm()\n",
       "            (1): SiLU()\n",
       "            (2): CausalConv3d(640, 640, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "            (3): RMS_norm()\n",
       "            (4): SiLU()\n",
       "            (5): Dropout(p=0.0, inplace=False)\n",
       "            (6): CausalConv3d(640, 640, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): RMS_norm()\n",
       "        (1): SiLU()\n",
       "        (2): CausalConv3d(640, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      )\n",
       "    )\n",
       "    (conv1): CausalConv3d(96, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (conv2): CausalConv3d(48, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (decoder): Decoder3d_38(\n",
       "      (conv1): CausalConv3d(48, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      (middle): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): RMS_norm()\n",
       "            (1): SiLU()\n",
       "            (2): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "            (3): RMS_norm()\n",
       "            (4): SiLU()\n",
       "            (5): Dropout(p=0.0, inplace=False)\n",
       "            (6): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): RMS_norm()\n",
       "          (to_qkv): Conv2d(1024, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (proj): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResidualBlock(\n",
       "          (residual): Sequential(\n",
       "            (0): RMS_norm()\n",
       "            (1): SiLU()\n",
       "            (2): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "            (3): RMS_norm()\n",
       "            (4): SiLU()\n",
       "            (5): Dropout(p=0.0, inplace=False)\n",
       "            (6): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "      )\n",
       "      (upsamples): Sequential(\n",
       "        (0): Up_ResidualBlock(\n",
       "          (avg_shortcut): DupUp3D()\n",
       "          (upsamples): Sequential(\n",
       "            (0): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (1): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (2): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (3): Resample38(\n",
       "              (resample): Sequential(\n",
       "                (0): Upsample(scale_factor=(2.0, 2.0), mode='nearest-exact')\n",
       "                (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (time_conv): CausalConv3d(1024, 2048, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Up_ResidualBlock(\n",
       "          (avg_shortcut): DupUp3D()\n",
       "          (upsamples): Sequential(\n",
       "            (0): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (1): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (2): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (3): Resample38(\n",
       "              (resample): Sequential(\n",
       "                (0): Upsample(scale_factor=(2.0, 2.0), mode='nearest-exact')\n",
       "                (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (time_conv): CausalConv3d(1024, 2048, kernel_size=(3, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): Up_ResidualBlock(\n",
       "          (avg_shortcut): DupUp3D()\n",
       "          (upsamples): Sequential(\n",
       "            (0): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(1024, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): CausalConv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (1): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (2): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (3): Resample38(\n",
       "              (resample): Sequential(\n",
       "                (0): Upsample(scale_factor=(2.0, 2.0), mode='nearest-exact')\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Up_ResidualBlock(\n",
       "          (upsamples): Sequential(\n",
       "            (0): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): CausalConv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            )\n",
       "            (1): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "            (2): ResidualBlock(\n",
       "              (residual): Sequential(\n",
       "                (0): RMS_norm()\n",
       "                (1): SiLU()\n",
       "                (2): CausalConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): RMS_norm()\n",
       "                (4): SiLU()\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "                (6): CausalConv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (head): Sequential(\n",
       "        (0): RMS_norm()\n",
       "        (1): SiLU()\n",
       "        (2): CausalConv3d(256, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from diffsynth import save_video, VideoData, load_state_dict\n",
    "from diffsynth.pipelines.wan_video_new import WanVideoPipeline, ModelConfig\n",
    "from modelscope import dataset_snapshot_download\n",
    "import numpy as np\n",
    "from utils import process_bracketed_video\n",
    "from utils import output_hdr_video, process_bracketed_video\n",
    "from utils import average_frame_psnr\n",
    "\n",
    "\n",
    "\n",
    "pipe = WanVideoPipeline.from_pretrained(\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device=\"cuda:5\",\n",
    "    model_configs=[\n",
    "        ModelConfig(model_id=\"Wan-AI/Wan2.2-TI2V-5B\", origin_file_pattern=\"models_t5_umt5-xxl-enc-bf16.pth\", offload_device=\"cpu\", skip_download=True),\n",
    "        ModelConfig(model_id=\"Wan-AI/Wan2.2-TI2V-5B\", origin_file_pattern=\"diffusion_pytorch_model*.safetensors\", offload_device=\"cpu\", skip_download=True),\n",
    "        ModelConfig(model_id=\"Wan-AI/Wan2.2-TI2V-5B\", origin_file_pattern=\"Wan2.2_VAE.pth\", offload_device=\"cpu\", skip_download=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "pipe.load_models_to_device([\"vae\"])\n",
    "\n",
    "# ensure the VAE is actually on the GPU in the right dtype\n",
    "pipe.vae = pipe.vae.to(device=pipe.device)\n",
    "pipe.vae.eval()  # optional but good practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "22a56195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RouteByType operator_map: [(<class 'str'>, <diffsynth.trainers.stuttgart_dataset.DataProcessingPipeline object at 0x14ad900ba6e0>)]\n",
      "MAX: 624.5 min: -0.14001465\n",
      "Image.shape (1080, 1920, 3) max value: 16.0\n",
      "tensor shape: torch.Size([3, 1080, 1920]) max value: tensor(16.)\n",
      "MAX: 690.0 min: -0.121032715\n",
      "Image.shape (1080, 1920, 3) max value: 16.0\n",
      "tensor shape: torch.Size([3, 1080, 1920]) max value: tensor(16.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX: 659.5 min: -0.13256836\n",
      "Image.shape (1080, 1920, 3) max value: 16.0\n",
      "tensor shape: torch.Size([3, 1080, 1920]) max value: tensor(16.)\n",
      "MAX: 629.0 min: -0.09844971\n",
      "Image.shape (1080, 1920, 3) max value: 16.0\n",
      "tensor shape: torch.Size([3, 1080, 1920]) max value: tensor(16.)\n"
     ]
    }
   ],
   "source": [
    "from diffsynth.trainers.stuttgart_dataset import StuttgartDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataset = StuttgartDataset(\n",
    "    base_path=\"/data2/saikiran.tedla/hdrvideo/diff/data/stuttgart/carousel_fireworks_02\",\n",
    "    repeat=1,\n",
    "    main_data_operator=StuttgartDataset.default_video_operator(\n",
    "        base_path=\"/data2/saikiran.tedla/hdrvideo/diff/data/stuttgart/carousel_fireworks_02\",\n",
    "        max_pixels=1280*720,\n",
    "        height=480,\n",
    "        width=832,\n",
    "        height_division_factor=16,\n",
    "        width_division_factor=16,\n",
    "        num_frames=13,\n",
    "        time_division_factor=4,\n",
    "        time_division_remainder=1,\n",
    "    ),\n",
    "    mode = \"hdr_and_brackets\"\n",
    ")\n",
    "\n",
    "data = dataset[50]\n",
    "bracket_video = data[\"video\"]\n",
    "#convert bracket video (list of PIL images) to tensor\n",
    "bracket_video = torch.stack([torch.from_numpy(np.array(img)).permute(2,0,1) for img in bracket_video], dim=0).float() / 255.0  # shape (T, C, H, W)\n",
    "hdr_video = torch.from_numpy(data[\"hdr_video\"])\n",
    "hdr_video = hdr_video.permute(0,3,1,2)  # shape (C, T, H, W)\n",
    "#reshape hdr_video to same H,W as bracket_video\n",
    "hdr_video = torch.nn.functional.interpolate(hdr_video, size=bracket_video.shape[2:], mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "bracket_video = bracket_video.unsqueeze(0).to(pipe.device).to(torch.bfloat16) \n",
    "hdr_video = hdr_video.unsqueeze(0).to(pipe.device).to(torch.bfloat16)\n",
    "#repeat the last hdr_video_frame so we get 5 frames\n",
    "hdr_video_padded = torch.cat([hdr_video[:,0:1], hdr_video], dim=1)\n",
    "\n",
    "normal_exposure = bracket_video[:, 1:5] #EV 0\n",
    "low_exposure = bracket_video[:, 5:9] #EV -4\n",
    "high_exposure = bracket_video[:, 9:13] #EV +4\n",
    "\n",
    "normal_exposure_padded = torch.cat([normal_exposure[:,0:1], normal_exposure], dim=1)\n",
    "low_exposure_padded = torch.cat([low_exposure[:,0:1], low_exposure], dim=1)\n",
    "high_exposure_padded = torch.cat([high_exposure[:,0:1], high_exposure], dim=1)\n",
    "#bracket_video[:, 5:9] = bracket_video[:, 5:9] ** (1/2)  # apply gamma correction to the normal exposure frames\n",
    "#bracket_video[:, 5:9] = bracket_video[:, 5:9] ** (1/2.2)  # apply gamma correction to the normal exposure frames\n",
    "\n",
    "bracket_with_pad = torch.cat([normal_exposure[:,0:1], normal_exposure, \n",
    "                                low_exposure[:, 0:1], low_exposure[:, 0:1], low_exposure[:, 0:1], low_exposure[:, 0:1], low_exposure,\n",
    "                                high_exposure[:, 0:1], high_exposure[:, 0:1], high_exposure[:, 0:1], high_exposure[:, 0:1], high_exposure\n",
    "                                ], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6f6dc6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded_bracket_video[0][1:] shape: torch.Size([12, 3, 480, 832])\n",
      "Using max:  16.0\n",
      "PSNR between decoded bracket video and original bracket video: 52.28 dB\n",
      "PSNR between decoded HDR video and original HDR video: 30.42 dB\n",
      "PSNR between bracket-to-HDR video and original HDR video: 27.48 dB\n",
      "PSNR between seperate bracket-to-HDR video and original HDR video: 30.43 dB\n",
      "PSNR between bracket with padding to HDR video and original HDR video: 29.86 dB\n"
     ]
    }
   ],
   "source": [
    "#read in mp4 video\n",
    "# mp4_path = \"/data2/saikiran.tedla/hdrvideo/diff/stuttgart_input.mp4\"\n",
    "# frames = VideoData(mp4_path, height=480, width=832).raw_data()\n",
    "#input_video = pipe.preprocess_video(frames)\n",
    "\n",
    "def encode_and_decode(video):\n",
    "    with torch.no_grad():\n",
    "        video = video * 2.0 - 1.0  # scale to [-1, 1]\n",
    "        video = video.permute(0,2,1,3,4)  # (B, T, C, H, W) to (B, C, T, H, W)\n",
    "        input_latents = pipe.vae.encode(video, device=pipe.device, tiled=False).to(dtype=pipe.torch_dtype, device=pipe.device)\n",
    "        output_video = pipe.vae.decode(input_latents, device=pipe.device, tiled=False).to(dtype=torch.float32, device=\"cpu\")\n",
    "        output_video = (output_video + 1.0) / 2.0  # scale to [0, 1]\n",
    "        output_video = torch.clamp(output_video, 0.0, 1.0) #clip output video to [0,1]\n",
    "        output_video = output_video.permute(0,2,1,3,4)  # (B, C, T, H, W) to (B, T, C, H, W)\n",
    "    return output_video\n",
    "\n",
    "decoded_bracket_video = encode_and_decode(bracket_video)\n",
    "decoded_normal_exposure = encode_and_decode(normal_exposure_padded)\n",
    "decoded_low_exposure = encode_and_decode(low_exposure_padded)\n",
    "decoded_high_exposure = encode_and_decode(high_exposure_padded)\n",
    "decoded_bracket_with_pad = encode_and_decode(bracket_with_pad)\n",
    "\n",
    "#combine the decoded exposures to get hdr video\n",
    "decoded_combined = torch.cat([decoded_normal_exposure[:, 1:5], decoded_low_exposure[:, 1:5],  decoded_high_exposure[:, 1:5]], dim=1)\n",
    "#remove padding\n",
    "decoded_bracket_with_pad = torch.cat([decoded_bracket_with_pad[:, 1:5], decoded_bracket_with_pad[:, 9:13], decoded_bracket_with_pad[:, 16:20]], dim=1)\n",
    "\n",
    "\n",
    "#encode and decode the hdr video\n",
    "max_hdr_value = torch.max(hdr_video)\n",
    "decoded_hdr_video_padded = encode_and_decode(hdr_video_padded/max_hdr_value) * max_hdr_value.cpu()\n",
    "decoded_hdr_video = decoded_hdr_video_padded[:, 1:]\n",
    "\n",
    "print(\"decoded_bracket_video[0][1:] shape:\", decoded_bracket_video[0][1:].shape)\n",
    "bracket_to_hdr_video = process_bracketed_video(decoded_bracket_video[0][1:]).unsqueeze(0)# with decoded\n",
    "seperate_bracket_to_hdr_video = process_bracketed_video(decoded_combined[0].to(dtype=torch.float32, device=\"cpu\")).unsqueeze(0) # with original bracket video\n",
    "bracket_w_pad_video = process_bracketed_video(decoded_bracket_with_pad[0].to(dtype=torch.float32, device=\"cpu\")).unsqueeze(0) # with original bracket video\n",
    "\n",
    "\n",
    "max_value = torch.max(hdr_video).item()\n",
    "print(\"Using max: \", max_value)\n",
    "psnr_bracket = average_frame_psnr(decoded_bracket_video, bracket_video, data_range=max_value)\n",
    "psnr_hdr = average_frame_psnr(decoded_hdr_video, hdr_video, data_range=max_value)\n",
    "psnr_bracket_to_hdr = average_frame_psnr(bracket_to_hdr_video, hdr_video, data_range=max_value)\n",
    "seperate_psnr_bracket_to_hdr = average_frame_psnr(seperate_bracket_to_hdr_video, hdr_video, data_range=max_value)\n",
    "psnr_bracket_w_pad = average_frame_psnr(bracket_w_pad_video, hdr_video, data_range=max_value)\n",
    "\n",
    "print(f\"PSNR between decoded bracket video and original bracket video: {psnr_bracket.item():.2f} dB\")\n",
    "print(f\"PSNR between decoded HDR video and original HDR video: {psnr_hdr.item():.2f} dB\")\n",
    "print(f\"PSNR between bracket-to-HDR video and original HDR video: {psnr_bracket_to_hdr.item():.2f} dB\")\n",
    "print(f\"PSNR between seperate bracket-to-HDR video and original HDR video: {seperate_psnr_bracket_to_hdr.item():.2f} dB\")\n",
    "print(f\"PSNR between bracket with padding to HDR video and original HDR video: {psnr_bracket_w_pad.item():.2f} dB\")\n",
    "# Save the videos for visual inspection\n",
    "output_hdr_video(decoded_bracket_video[0], \"/data2/saikiran.tedla/hdrvideo/diff/encoder_test/decoded_bracket_video\")\n",
    "output_hdr_video(decoded_hdr_video[0], \"/data2/saikiran.tedla/hdrvideo/diff/encoder_test/decoded_hdr_video\")\n",
    "output_hdr_video(bracket_video[0].to(dtype=torch.float32, device=\"cpu\"), \"/data2/saikiran.tedla/hdrvideo/diff/encoder_test/original_bracket_video\")\n",
    "output_hdr_video(hdr_video[0].to(dtype=torch.float32, device=\"cpu\"), \"/data2/saikiran.tedla/hdrvideo/diff/encoder_test/original_hdr_video\")\n",
    "output_hdr_video(bracket_to_hdr_video[0], \"/data2/saikiran.tedla/hdrvideo/diff/encoder_test/bracket_to_hdr_video\")\n",
    "output_hdr_video(seperate_bracket_to_hdr_video[0], \"/data2/saikiran.tedla/hdrvideo/diff/encoder_test/seperate_bracket_to_hdr_video\")\n",
    "output_hdr_video(bracket_w_pad_video[0], \"/data2/saikiran.tedla/hdrvideo/diff/encoder_test/bracket_with_pad_to_hdr_video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca84d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anyedit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
